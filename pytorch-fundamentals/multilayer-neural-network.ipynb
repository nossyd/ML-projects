{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bb78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7eb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    # parameterize num of inputs & outputs to reuse same code for diff datasets with diff num of features and classes\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "\n",
    "            # first hidden layer\n",
    "            # Linear layer takes num of input and output nodes as args\n",
    "            torch.nn.Linear(num_inputs, 30),\n",
    "            # Nonlinear activation functions are placed bw hidden layers\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # second hidden layer\n",
    "            # The num of output nodes in prev hidden layer is equal to input of next hidden layer\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output layer\n",
    "            torch.nn.Linear(20, num_outputs),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        # the output of the last layer are called logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35a3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee30161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2327d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters:  2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb030f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0392, -0.0775, -0.0300,  ...,  0.1131,  0.1076, -0.0769],\n",
      "        [-0.0138,  0.0322, -0.0596,  ...,  0.0396, -0.0206,  0.1047],\n",
      "        [-0.1298,  0.0083, -0.0049,  ..., -0.0868,  0.0101,  0.0912],\n",
      "        ...,\n",
      "        [ 0.0066,  0.0942, -0.0337,  ..., -0.0089,  0.1274, -0.0954],\n",
      "        [-0.0613, -0.1061,  0.0324,  ..., -0.1378,  0.0567, -0.1304],\n",
      "        [ 0.0922, -0.1069,  0.0259,  ...,  0.0429, -0.1194, -0.1237]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# access weight parameter matrix from first Linear layer\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac070bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "# shape of weight parameter matrix from first Linear layer\n",
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea127f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0327,  0.0788,  0.0992,  0.1292, -0.1204,  0.0609,  0.1022, -0.0856,\n",
      "        -0.1064,  0.0502, -0.0154, -0.1026, -0.1351, -0.0687,  0.0022,  0.1350,\n",
      "        -0.0332, -0.0419, -0.0697, -0.0032,  0.1289,  0.1124, -0.0852, -0.0603,\n",
      "         0.0642,  0.0202,  0.0840,  0.0076, -0.0215,  0.1272],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# access bias parameter matrix from first Linear layer\n",
    "print(model.layers[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc44454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# shape of bias parameter matrix from first Linear layer\n",
    "print(model.layers[0].bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160a914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
