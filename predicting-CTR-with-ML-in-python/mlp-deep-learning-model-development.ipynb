{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, auc, accuracy_score, roc_auc_score, fbeta_score\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/dysson/Downloads/train.gz',compression='gzip')\n",
    "df_train.rename(columns = {'C1': 'search_engine_type', 'C14': 'product_type', 'C15': 'advertiser_type'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da75ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df_train.loc[:, ~df_train.columns.isin(['click'])]\n",
    "y = df_train.click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduce = X[['hour', 'search_engine_type', 'banner_pos', 'device_type', 'device_conn_type', 'product_type', 'advertiser_type', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up classifier using training data to predict test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X_reduce, y, test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47a7a7",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features and split into training and testing\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c870b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier and produce predictions\n",
    "clf = MLPClassifier(hidden_layer_sizes = (8, ), max_iter = 100)\n",
    "y_score = clf.fit(X_train, y_train).predict_proba(X_test) \n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy and AUC of ROC curve \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Accuracy: %s\" %(accuracy_score(y_test, y_pred)))\n",
    "print(\"ROC of AUC curve: %s\" %(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f977d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over various max_iter configurations\n",
    "max_iter_list = [10, 20, 30]\n",
    "for max_iter in max_iter_list:\n",
    "\tclf = MLPClassifier(hidden_layer_sizes = (4, ), \n",
    "                        max_iter = max_iter, random_state = 0)\n",
    "   \t# Extract relevant predictions\n",
    "\ty_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "\ty_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\t# Get ROC curve metrics\n",
    "\tprint(\"Accuracy for max_iter = %s: %s\" %(\n",
    "      max_iter, accuracy_score(y_test, y_pred)))\n",
    "\tprint(\"AUC for max_iter = %s: %s\" %(\n",
    "      max_iter, roc_auc_score(y_test, y_score[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and loop over various hidden_layer_sizes configurations\n",
    "hidden_layer_sizes_list = [(4,), (8,), (16,)]\n",
    "for hidden_layer_sizes in hidden_layer_sizes_list:\n",
    "\tclf = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, \n",
    "                        max_iter = 10, random_state = 0)\n",
    "   \t# Extract relevant predictions\n",
    "\ty_score = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "\ty_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\t# Get ROC curve metrics\n",
    "\tprint(\"Accuracy for hidden_layer_sizes = %s: %s\" %(\n",
    "      hidden_layer_sizes, accuracy_score(y_test, y_pred)))\n",
    "\tprint(\"AUC for hidden_layer_sizes = %s: %s\" %(\n",
    "      hidden_layer_sizes, roc_auc_score(y_test, y_score[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hyperparameters \n",
    "max_iter = [10, 20]\n",
    "hidden_layer_sizes = [(8,), (16,)]\n",
    "param_grid = {'max_iter': max_iter, 'hidden_layer_sizes': hidden_layer_sizes}\n",
    "\n",
    "# Use Grid search CV to find best parameters using 4 jobs\n",
    "mlp = MLPClassifier()\n",
    "clf = GridSearchCV(estimator = mlp, param_grid = param_grid, \n",
    "           scoring = 'roc_auc', n_jobs = 4)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best Score: \")\n",
    "print(clf.best_score_)\n",
    "print(\"Best Estimator: \")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION: ROI on ad spend through clicks\n",
    "## Low precision --> little tangible ROI on clicks (may be prioritized for business bc tangible ROI)\n",
    "\n",
    "# Recall: targeting relevant audience\n",
    "## Low recall --> missed opportunities on ROI\n",
    "\n",
    "# F-beta score: weighted harmonic mean bw precision and recall and thus will always lay bw precision and recall but will be closer to the less of two values\n",
    "## beta coefficient is how much want to weight the two metrcs: \n",
    "# beta = 1 --> equal weightage\n",
    "# 0 < beta < 1 --> precision is made smaller and thus more weighted\n",
    "# beta > 1 --> recall is made smaller and thus more weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLP classifier, train and predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size = .2, random_state = 0)\n",
    "clf = MLPClassifier(hidden_layer_sizes = (16, ), \n",
    "                    max_iter = 10, random_state = 0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test) \n",
    "\n",
    "# Evaluate precision and recall\n",
    "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "fbeta = fbeta_score(y_test, y_pred, beta  = 0.5, average = 'weighted')\n",
    "print(\"Precision: %s, Recall: %s, F-beta score: %s\" %(prec, recall, fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precision and total ROI\n",
    "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "r = 0.2\n",
    "cost = 0.05 \n",
    "roi = prec * r / cost\n",
    "\n",
    "# Get AUC\n",
    "roc_auc = roc_auc_score(y_test, y_score[:, 1])\n",
    "\n",
    "print(\"Total ROI: %s, Precision: %s, AUC of ROC curve: %s\" %(\n",
    "  roi, prec, roc_auc))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
