{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00ee9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, auc\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61a65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/dysson/Downloads/train.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262693c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns = {'C1': 'search_engine_type', 'C14': 'product_type', 'C15': 'advertiser_type'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f310a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df_train.loc[:, ~df_train.columns.isin(['click'])]\n",
    "y = df_train.click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a75423",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduce = X[['hour', 'search_engine_type', 'banner_pos', 'device_type', 'device_conn_type', 'product_type', 'advertiser_type', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ea01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up classifier using training data to predict test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X_reduce, y, test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000cc9b4",
   "metadata": {},
   "source": [
    "### DT classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d948c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157e6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: \n",
      " [[6617757   94278]\n",
      " [1269830  103929]]\n",
      "\n",
      "TN: 6617757, FP: 94278, FN: 1269830, TP: 103929\n"
     ]
    }
   ],
   "source": [
    "# Define confusion matrix and four categories\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn = conf_matrix[0][0]\n",
    "fp = conf_matrix[0][1]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "\n",
    "print(\"confusion_matrix: \\n\", conf_matrix)\n",
    "print(\"\\nTN: %s, FP: %s, FN: %s, TP: %s\" %(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9419a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix and get four categories\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5b2eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total return: 20785.8 \n",
      "Total cost: 9910.35 \n",
      "ROI: 2.0974\n"
     ]
    }
   ],
   "source": [
    "# Calculate total return, total spent, and ROI\n",
    "r = 0.2\n",
    "cost = 0.05\n",
    "total_return = calc_total_return(tp=tp , r=r)\n",
    "total_cost = calc_total_cost(fp=fp, tp=tp, cost=cost)\n",
    "roi = calc_roi(total_return=total_return, total_cost=total_cost)\n",
    "print(\"Total return: %s \\nTotal cost: %s \\nROI: %s\" %(\n",
    "  round(total_return,2), round(total_cost,2), round(roi,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dfe0506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7855484472239275, Recall: 0.8312957268018453\n"
     ]
    }
   ],
   "source": [
    "# Evaluate precision and recall\n",
    "## using average = 'weighted' bc class imbalance; \n",
    "## from docs: 'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters 'macro' to account for label imbalance; \n",
    "## it can result in an F-score that is not between precision and recall.\n",
    "prec = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "print(\"Precision: %s, Recall: %s\" %(prec, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084bea3",
   "metadata": {},
   "source": [
    "#### regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34a481df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tree with max_depth = 2\n",
      "Confusion matrix: \n",
      "[[6712035       0]\n",
      " [1373759       0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6890695827491409, Recall: 0.8301021519964521\n",
      "Evaluating tree with max_depth = 3\n",
      "Confusion matrix: \n",
      "[[6712035       0]\n",
      " [1373759       0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6890695827491409, Recall: 0.8301021519964521\n",
      "Evaluating tree with max_depth = 5\n",
      "Confusion matrix: \n",
      "[[6630569   81466]\n",
      " [1283819   89940]]\n",
      "Precision: 0.7845971859152628, Recall: 0.8311501628658855\n",
      "Evaluating tree with max_depth = 10\n",
      "Confusion matrix: \n",
      "[[6639324   72711]\n",
      " [1280889   92870]]\n",
      "Precision: 0.7911458677939663, Recall: 0.832595289961629\n",
      "Evaluating tree with max_depth = 15\n",
      "Confusion matrix: \n",
      "[[6634001   78034]\n",
      " [1271836  101923]]\n",
      "Precision: 0.7927868545893796, Recall: 0.8330565928342968\n",
      "Evaluating tree with max_depth = 20\n",
      "Confusion matrix: \n",
      "[[6633361   78674]\n",
      " [1273656  100103]]\n",
      "Precision: 0.7915212354082443, Recall: 0.8327523555509824\n"
     ]
    }
   ],
   "source": [
    "# Iterate over different levels of max depth\n",
    "for max_depth_val in [2, 3, 5, 10, 15, 20]:\n",
    "  # Create and fit model\n",
    "  clf = DecisionTreeClassifier(max_depth = max_depth_val)\n",
    "  print(\"Evaluating tree with max_depth = %s\" %(max_depth_val))\n",
    "  y_pred_reg = clf.fit(X_train, y_train).predict(X_test) \n",
    "  \n",
    "  # Evaluate confusion matrix, precision, recall\n",
    "  print(\"Confusion matrix: \")\n",
    "  print(confusion_matrix(y_test, y_pred_reg))\n",
    "  prec = precision_score(y_test, y_pred_reg, average = 'weighted')\n",
    "  recall = recall_score(y_test, y_pred_reg, average = 'weighted')\n",
    "  print(\"Precision: %s, Recall: %s\" %(prec, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1413858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision scores: [0.79090516 0.79046005 0.79110235 0.79074976]\n",
      "Recall scores: [0.83265169 0.83243548 0.83291732 0.83269977]\n"
     ]
    }
   ],
   "source": [
    "# Set up k-fold\n",
    "k_fold = KFold(n_splits = 4, random_state = 0, shuffle = True)\n",
    "\n",
    "# Evaluate precision and recall for each fold\n",
    "precision = cross_val_score(\n",
    "  clf, X_train, y_train, cv = k_fold, scoring = 'precision_weighted')\n",
    "recall = cross_val_score(\n",
    "  clf, X_train, y_train, cv = k_fold, scoring = 'recall_weighted')\n",
    "print(\"Precision scores: %s\" %(precision)) \n",
    "print(\"Recall scores: %s\" %(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19f828a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree for max_depth = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation Precision: [0.68913118 0.68891803 0.68962855 0.68936627]\n",
      "Test Precision: 0.6890695827491409\n",
      "Evaluating Decision Tree for max_depth = 5\n",
      "Cross validation Precision: [0.78438442 0.78405002 0.78430679 0.78443541]\n",
      "Test Precision: 0.7845971859152628\n",
      "Evaluating Decision Tree for max_depth = 10\n",
      "Cross validation Precision: [0.79115099 0.79007214 0.79030502 0.79121424]\n",
      "Test Precision: 0.7911458677939663\n"
     ]
    }
   ],
   "source": [
    "# Iterate over different levels of max depth and set up k-fold\n",
    "for max_depth_val in [3, 5, 10]:\n",
    "  k_fold = KFold(n_splits = 4, random_state = 0, shuffle = True)\n",
    "  clf = DecisionTreeClassifier(max_depth = max_depth_val)\n",
    "  print(\"Evaluating Decision Tree for max_depth = %s\" %(max_depth_val))\n",
    "  y_pred = clf.fit(X_train, y_train).predict(X_test) \n",
    "  \n",
    "  # Calculate precision for cross validation and test\n",
    "  cv_precision = cross_val_score(\n",
    "    clf, X_train, y_train, cv = k_fold, scoring = 'precision_weighted')\n",
    "  precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "  print(\"Cross validation Precision: %s\" %(cv_precision))\n",
    "  print(\"Test Precision: %s\" %(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2e6c0",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4645c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest classifier with specified params\n",
    "clf = RandomForestClassifier(n_estimators = 50, max_depth = 5)\n",
    "\n",
    "# Train classifier - predict probability score and label\n",
    "## To get the probabilities, use predict_proba() instead of predict()\n",
    "y_score = clf.fit(X_train, y_train).predict_proba(X_test) \n",
    "## intended to be predicted class label thus using predict() instead of predict_proba()\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd15451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROC curve metrics\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])\n",
    "print(\"ROC of AUC: %s\"%(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precision and recall\n",
    "precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "print(\"Precision: %s, Recall: %s\" %(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430aeff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hyperparameters \n",
    "n_estimators = [10, 50]\n",
    "max_depth = [5, 20]\n",
    "param_grid = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "# Use Grid search CV to find best parameters \n",
    "print(\"starting RF grid search.. \")\n",
    "rf = RandomForestClassifier()\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid, scoring = 'roc_auc')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \")\n",
    "print(clf.best_score_)\n",
    "print(\"Best Estimator: \")\n",
    "print(clf.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
